{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f36ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file (replace 'dataset.csv' with your actual file path)\n",
    "data = pd.read_csv('StudentPerformanceFactors.csv')\n",
    "\n",
    "# Drop excluded features\n",
    "excluded_features = ['Family_Income', 'Parental_Involvement', 'Physical_Activity', 'Distance_from_Home',\n",
    "                     'Motivation_Level', 'Tutoring_Sessions', 'Parental_Education_Level']\n",
    "data = data.drop(columns=excluded_features)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe76f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature constraints for remaining features\n",
    "feature_constraints = {\n",
    "    'Hours_Studied': {'type': 'numerical', 'min': 0, 'max': 50},\n",
    "    'Attendance': {'type': 'numerical', 'min': 0, 'max': 100},\n",
    "    'Access_to_Resources': {'type': 'categorical', 'values': ['Low', 'Medium', 'High']},\n",
    "    'Extracurricular_Activities': {'type': 'categorical', 'values': ['Yes', 'No']},\n",
    "    'Sleep_Hours': {'type': 'numerical', 'min': 0, 'max': 24},\n",
    "    'Previous_Scores': {'type': 'numerical', 'min': 0, 'max': 100},\n",
    "    'Internet_Access': {'type': 'categorical', 'values': ['Yes', 'No']},\n",
    "    'Teacher_Quality': {'type': 'categorical', 'values': ['Low', 'Medium', 'High']},\n",
    "    'School_Type': {'type': 'categorical', 'values': ['Public', 'Private']},\n",
    "    'Peer_Influence': {'type': 'categorical', 'values': ['Positive', 'Negative', 'Neutral']},\n",
    "    'Learning_Disabilities': {'type': 'categorical', 'values': ['Yes', 'No']},\n",
    "    'Gender': {'type': 'categorical', 'values': ['Male', 'Female']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa353502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical and categorical columns\n",
    "numerical_cols = [col for col, spec in feature_constraints.items() if spec['type'] == 'numerical']\n",
    "categorical_cols = [col for col, spec in feature_constraints.items() if spec['type'] == 'categorical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d161cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split features and target\n",
    "X = data.drop('Exam_Score', axis=1)\n",
    "y = data['Exam_Score']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08172c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', SGDRegressor(max_iter=1, tol=None, learning_rate='constant', eta0=0.01, random_state=42))\n",
    "    ]),\n",
    "    'Decision Tree': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "    ]),\n",
    "    'Random Forest': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "262e7a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models and collect performance metrics\n",
    "results = {}\n",
    "train_losses = {'Linear Regression': [], 'Decision Tree': [], 'Random Forest': []}\n",
    "test_losses = {'Linear Regression': [], 'Decision Tree': [], 'Random Forest': []}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'Linear Regression':\n",
    "        # Simulate epochs for SGDRegressor\n",
    "        n_epochs = 100\n",
    "        for epoch in range(n_epochs):\n",
    "            model.fit(X_train, y_train)  # Partial fit for SGDRegressor\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            train_losses[name].append(mean_squared_error(y_train, y_train_pred))\n",
    "            test_losses[name].append(mean_squared_error(y_test, y_test_pred))\n",
    "    else:\n",
    "        # Train Decision Tree and Random Forest (single fit)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        train_losses[name].append(mean_squared_error(y_train, y_train_pred))\n",
    "        test_losses[name].append(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "    # Final performance metrics\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_test_pred)\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "    results[name] = {'MSE': mse, 'R2': r2, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name in models.keys():\n",
    "    if name == 'Linear Regression':\n",
    "        plt.plot(range(n_epochs), train_losses[name], label=f'{name} Train Loss')\n",
    "        plt.plot(range(n_epochs), test_losses[name], label=f'{name} Test Loss', linestyle='--')\n",
    "    else:\n",
    "        plt.scatter([0], train_losses[name], label=f'{name} Train Loss', marker='o')\n",
    "        plt.scatter([0], test_losses[name], label=f'{name} Test Loss', marker='x')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Training and Test Loss Curves')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_curves.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter plot for Linear Regression\n",
    "lr_model = models['Linear Regression']\n",
    "y_test_pred_lr = lr_model.predict(X_test)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_pred_lr, alpha=0.5, label='Predictions')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Ideal Line')\n",
    "plt.xlabel('Actual Exam Score')\n",
    "plt.ylabel('Predicted Exam Score')\n",
    "plt.title('Linear Regression: Actual vs Predicted Exam Scores')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('lr_scatter.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "print(\"\\nModel Comparison:\")\n",
    "best_model_name = min(results, key=lambda x: results[x]['MSE'])\n",
    "best_mse = results[best_model_name]['MSE']\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  MSE: {metrics['MSE']:.2f}\")\n",
    "    print(f\"  R2: {metrics['R2']:.2f}\")\n",
    "    if name == best_model_name:\n",
    "        print(\"  (Best Model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34fdd2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input():\n",
    "    \"\"\"Prompt user to enter values for each feature and validate them.\"\"\"\n",
    "    user_data = {}\n",
    "    for feature, spec in feature_constraints.items():\n",
    "        while True:\n",
    "            try:\n",
    "                if spec['type'] == 'numerical':\n",
    "                    value = float(input(f\"Enter {feature} ({spec['min']} to {spec['max']}): \"))\n",
    "                    if spec['min'] <= value <= spec['max']:\n",
    "                        user_data[feature] = value\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"Value must be between {spec['min']} and {spec['max']}.\")\n",
    "                else:  # categorical\n",
    "                    print(f\"Enter {feature} (valid options: {', '.join(spec['values'])}): \")\n",
    "                    value = input().strip().capitalize()\n",
    "                    if value in spec['values']:\n",
    "                        user_data[feature] = value\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"Invalid option. Choose from: {', '.join(spec['values'])}.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a valid number for numerical features.\")\n",
    "    return pd.DataFrame([user_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3c852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the following information to predict your Exam Score:\n"
     ]
    }
   ],
   "source": [
    "def predict_exam_score():\n",
    "    \"\"\"Predict Exam_Score based on user input using the best model.\"\"\"\n",
    "    print(\"Enter the following information to predict your Exam Score:\")\n",
    "    user_input = get_user_input()\n",
    "\n",
    "    # Load the best model\n",
    "    best_model = joblib.load('best_model.pkl')\n",
    "    prediction = best_model.predict(user_input)[0]\n",
    "\n",
    "    print(f\"\\nPredicted Exam Score: {prediction:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predict_exam_score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
